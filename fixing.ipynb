{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkHwicQDrZ4H",
        "outputId": "6fc334ec-bac2-4316-e737-f4a5baa3a4f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCoieubRPRgE"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfZfkb5Ereuu"
      },
      "outputs": [],
      "source": [
        "import timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcxRLYrpkh2N",
        "outputId": "ffe93962-2651-47c6-e5e7-039245cc21c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://data.csail.mit.edu/places/places365/filelist_places365-standard.tar to ./datasets/filelist_places365-standard.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 67498496/67498496 [00:01<00:00, 62367841.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/filelist_places365-standard.tar to ./datasets\n",
            "Downloading https://data.csail.mit.edu/places/places365/train_256_places365standard.tar to ./datasets/train_256_places365standard.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26103685120/26103685120 [05:35<00:00, 77710003.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/train_256_places365standard.tar to ./datasets\n"
          ]
        }
      ],
      "source": [
        "data = torchvision.datasets.Places365(root='./datasets', split='train-standard', small=True, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ft_5-YelRF1"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import Places365"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL3e0HWFPRgE"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbLl-ZWxPRgE"
      },
      "outputs": [],
      "source": [
        "def label_func(fname):\n",
        "    if len(Path(fname).parent.name) > 2:\n",
        "        return Path(fname).parent.name + Path(fname).parent.parent.name\n",
        "    else:\n",
        "        return Path(fname).parent.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FsoxsAJPRgF"
      },
      "outputs": [],
      "source": [
        "data_prop = DataBlock(\n",
        "    blocks = (ImageBlock,CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    splitter = RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y = label_func,\n",
        "    item_tfms = RandomResizedCrop(256, min_scale=0.9),\n",
        "    batch_tfms = aug_transforms()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU8qvFmZPRgF"
      },
      "outputs": [],
      "source": [
        "data_prop2 = DataBlock(\n",
        "    blocks = (ImageBlock,CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    splitter = RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y = label_func,\n",
        "    item_tfms = Resize((224, 224)),\n",
        "    batch_tfms = aug_transforms()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEBFV5hdPRgF"
      },
      "outputs": [],
      "source": [
        "dls  = data_prop.dataloaders('./datasets/data_256_standard/', bs=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfrrLWvbPRgF"
      },
      "outputs": [],
      "source": [
        "dls2 = data_prop2.dataloaders('./datasets/data_256_standard/', bs=224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31KVmz7SPRgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6760bfd1-78b0-400d-fed9-c1bf3d5c26eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "learner1 =vision_learner(dls, 'resnet50d.ra2_in1k' ,metrics=[error_rate, accuracy, top_k_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khZw4aJgPRgG"
      },
      "outputs": [],
      "source": [
        "learner2 =vision_learner(dls2, 'coatnet_nano_rw_224.sw_in1k' ,metrics=[error_rate, accuracy, top_k_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2og1MsMqPRgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c917ea7-2bad-46c2-f43a-5595322112bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/learner.py:59: UserWarning: Saved file doesn't contain an optimizer state.\n",
            "  elif with_opt: warn(\"Saved file doesn't contain an optimizer state.\")\n"
          ]
        }
      ],
      "source": [
        "learner1 = learner1.load('Myresnet50d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XphLXPmVPRgH"
      },
      "outputs": [],
      "source": [
        "#import pathlib\n",
        "#plt = platform.system()\n",
        "#if plt == 'Windows': pathlib.PosixPath = pathlib.WindowsPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmF5RWdAPRgH"
      },
      "outputs": [],
      "source": [
        "learner2 = load_learner('coatnet.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STcCHJlnPRgI"
      },
      "outputs": [],
      "source": [
        "model1= learner1.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbZOzT4jPRgI"
      },
      "outputs": [],
      "source": [
        "model2= learner2.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elRV04j6PRgI"
      },
      "outputs": [],
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2fFptVFPRgJ"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device =  torch.device('cuda')\n",
        "else:\n",
        "    device =  torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNX8dBJFPRgJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "OUR_CLASSES=365"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQyMSgIpPRgJ"
      },
      "outputs": [],
      "source": [
        "class HybridN(torch.nn.Module):\n",
        "    def __init__(self, model1, model2) -> None:\n",
        "        super(HybridN, self).__init__()\n",
        "        self.mdl1 = model1\n",
        "        self.mdl2 = model2\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=OUR_CLASSES*2, out_features=512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512,365)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mdl1.eval()\n",
        "        self.mdl2.eval()\n",
        "        out1 = self.mdl1(x)\n",
        "        out2 = self.mdl2(x)\n",
        "        out = torch.cat((out1, out2), dim=1)\n",
        "        x = self.fc(out)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycYikaYnPRgJ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa61c74a-fd22-4cb6-d730-4a82c6e616b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HybridN(\n",
              "  (mdl1): Sequential(\n",
              "    (0): TimmBody(\n",
              "      (model): ResNet(\n",
              "        (conv1): Sequential(\n",
              "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "          (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "        (layer1): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): Identity()\n",
              "              (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer2): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "              (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer3): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "              (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (3): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (4): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (5): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (layer4): Sequential(\n",
              "          (0): Bottleneck(\n",
              "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "            (downsample): Sequential(\n",
              "              (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "              (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (1): Bottleneck(\n",
              "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Bottleneck(\n",
              "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act1): ReLU(inplace=True)\n",
              "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (drop_block): Identity()\n",
              "            (act2): ReLU(inplace=True)\n",
              "            (aa): Identity()\n",
              "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (act3): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "        (fc): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): AdaptiveConcatPool2d(\n",
              "        (ap): AdaptiveAvgPool2d(output_size=1)\n",
              "        (mp): AdaptiveMaxPool2d(output_size=1)\n",
              "      )\n",
              "      (1): fastai.layers.Flatten(full=False)\n",
              "      (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): Dropout(p=0.25, inplace=False)\n",
              "      (4): Linear(in_features=4096, out_features=512, bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (7): Dropout(p=0.5, inplace=False)\n",
              "      (8): Linear(in_features=512, out_features=365, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (mdl2): Sequential(\n",
              "    (0): TimmBody(\n",
              "      (model): MaxxVit(\n",
              "        (stem): Stem(\n",
              "          (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (norm1): BatchNormAct2d(\n",
              "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        )\n",
              "        (stages): Sequential(\n",
              "          (0): MaxxVitStage(\n",
              "            (blocks): Sequential(\n",
              "              (0): MbConvBlock(\n",
              "                (shortcut): Downsample2d(\n",
              "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                  (expand): Identity()\n",
              "                )\n",
              "                (pre_norm): BatchNormAct2d(\n",
              "                  64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): Identity()\n",
              "                )\n",
              "                (down): Downsample2d(\n",
              "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                  (expand): Identity()\n",
              "                )\n",
              "                (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (norm1): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "                (norm2): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (se): SEModule(\n",
              "                  (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (bn): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (gate): Sigmoid()\n",
              "                )\n",
              "                (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (drop_path): Identity()\n",
              "              )\n",
              "              (1): MbConvBlock(\n",
              "                (shortcut): Identity()\n",
              "                (pre_norm): BatchNormAct2d(\n",
              "                  64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): Identity()\n",
              "                )\n",
              "                (down): Identity()\n",
              "                (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (norm1): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "                (norm2): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (se): SEModule(\n",
              "                  (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (bn): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (gate): Sigmoid()\n",
              "                )\n",
              "                (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (drop_path): Identity()\n",
              "              )\n",
              "              (2): MbConvBlock(\n",
              "                (shortcut): Identity()\n",
              "                (pre_norm): BatchNormAct2d(\n",
              "                  64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): Identity()\n",
              "                )\n",
              "                (down): Identity()\n",
              "                (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (norm1): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "                (norm2): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (se): SEModule(\n",
              "                  (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (bn): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (gate): Sigmoid()\n",
              "                )\n",
              "                (conv3_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (drop_path): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): MaxxVitStage(\n",
              "            (blocks): Sequential(\n",
              "              (0): MbConvBlock(\n",
              "                (shortcut): Downsample2d(\n",
              "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                  (expand): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (pre_norm): BatchNormAct2d(\n",
              "                  64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): Identity()\n",
              "                )\n",
              "                (down): Downsample2d(\n",
              "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                  (expand): Identity()\n",
              "                )\n",
              "                (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (norm1): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "                (norm2): BatchNormAct2d(\n",
              "                  256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (se): SEModule(\n",
              "                  (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (bn): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (gate): Sigmoid()\n",
              "                )\n",
              "                (conv3_1x1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (drop_path): Identity()\n",
              "              )\n",
              "              (1): MbConvBlock(\n",
              "                (shortcut): Identity()\n",
              "                (pre_norm): BatchNormAct2d(\n",
              "                  128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): Identity()\n",
              "                )\n",
              "                (down): Identity()\n",
              "                (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (norm1): BatchNormAct2d(\n",
              "                  512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "                (norm2): BatchNormAct2d(\n",
              "                  512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (se): SEModule(\n",
              "                  (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (bn): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (gate): Sigmoid()\n",
              "                )\n",
              "                (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (drop_path): Identity()\n",
              "              )\n",
              "              (2): MbConvBlock(\n",
              "                (shortcut): Identity()\n",
              "                (pre_norm): BatchNormAct2d(\n",
              "                  128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): Identity()\n",
              "                )\n",
              "                (down): Identity()\n",
              "                (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (norm1): BatchNormAct2d(\n",
              "                  512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "                (norm2): BatchNormAct2d(\n",
              "                  512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (se): SEModule(\n",
              "                  (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (bn): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (gate): Sigmoid()\n",
              "                )\n",
              "                (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (drop_path): Identity()\n",
              "              )\n",
              "              (3): MbConvBlock(\n",
              "                (shortcut): Identity()\n",
              "                (pre_norm): BatchNormAct2d(\n",
              "                  128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): Identity()\n",
              "                )\n",
              "                (down): Identity()\n",
              "                (conv1_1x1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (norm1): BatchNormAct2d(\n",
              "                  512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (conv2_kxk): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
              "                (norm2): BatchNormAct2d(\n",
              "                  512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "                  (drop): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (se): SEModule(\n",
              "                  (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (bn): Identity()\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (gate): Sigmoid()\n",
              "                )\n",
              "                (conv3_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (drop_path): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (2): MaxxVitStage(\n",
              "            (blocks): Sequential(\n",
              "              (0): TransformerBlock2d(\n",
              "                (shortcut): Downsample2d(\n",
              "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                  (expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (norm1): Sequential(\n",
              "                  (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
              "                  (down): Downsample2d(\n",
              "                    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                    (expand): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "              (1): TransformerBlock2d(\n",
              "                (shortcut): Identity()\n",
              "                (norm1): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "              (2): TransformerBlock2d(\n",
              "                (shortcut): Identity()\n",
              "                (norm1): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "              (3): TransformerBlock2d(\n",
              "                (shortcut): Identity()\n",
              "                (norm1): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "              (4): TransformerBlock2d(\n",
              "                (shortcut): Identity()\n",
              "                (norm1): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "              (5): TransformerBlock2d(\n",
              "                (shortcut): Identity()\n",
              "                (norm1): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (3): MaxxVitStage(\n",
              "            (blocks): Sequential(\n",
              "              (0): TransformerBlock2d(\n",
              "                (shortcut): Downsample2d(\n",
              "                  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                  (expand): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (norm1): Sequential(\n",
              "                  (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
              "                  (down): Downsample2d(\n",
              "                    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "                    (expand): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "              (1): TransformerBlock2d(\n",
              "                (shortcut): Identity()\n",
              "                (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "              (2): TransformerBlock2d(\n",
              "                (shortcut): Identity()\n",
              "                (norm1): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
              "                (attn): Attention2d(\n",
              "                  (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (rel_pos): RelPosBias()\n",
              "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "                  (proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (ls1): Identity()\n",
              "                (drop_path1): Identity()\n",
              "                (norm2): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
              "                (mlp): ConvMlp(\n",
              "                  (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "                  (norm): Identity()\n",
              "                  (act): GELU()\n",
              "                  (drop): Dropout(p=0.0, inplace=False)\n",
              "                  (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "                )\n",
              "                (ls2): Identity()\n",
              "                (drop_path2): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (norm): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
              "        (head): ClassifierHead(\n",
              "          (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "          (fc): Identity()\n",
              "          (flatten): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): AdaptiveConcatPool2d(\n",
              "        (ap): AdaptiveAvgPool2d(output_size=1)\n",
              "        (mp): AdaptiveMaxPool2d(output_size=1)\n",
              "      )\n",
              "      (1): fastai.layers.Flatten(full=False)\n",
              "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): Dropout(p=0.25, inplace=False)\n",
              "      (4): Linear(in_features=1024, out_features=512, bias=False)\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (7): Dropout(p=0.5, inplace=False)\n",
              "      (8): Linear(in_features=512, out_features=365, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=730, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=365, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "to_device(model1, device)\n",
        "to_device(model2, device)\n",
        "big = HybridN(model1, model2)\n",
        "to_device(big, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtMz5TbEPRgJ"
      },
      "outputs": [],
      "source": [
        "root_dir = './datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ2yRYGsPRgK"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9BM9J1APRgK"
      },
      "outputs": [],
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ColorJitter(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                                transforms.Resize(224),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_data = Places365(root=root_dir, split='train-standard', small=True, download=False, transform=train_transform)\n",
        "test_data = Places365(root=root_dir, split='val', small=True, download=False, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdz-aM_lPRgK"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYcjAXqNPRgK"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Esk1Cbu9PRgK"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(big.fc.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60uzxCkUPRgK"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device =  torch.device('cuda')\n",
        "else:\n",
        "    device =  torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO-LtdRLPRgL"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = big(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(train_loader) + i + 1\n",
        "            running_loss = 0.\n",
        "\n",
        "\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return last_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjI_pPgqPRgL"
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsNRAhvV5lao"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRU9-d_kPRgL",
        "outputId": "7dcb9180-48c1-44f5-b05e-76eeba1d5d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.3296201545000077\n",
            "  batch 2000 loss: 2.0179916833639147\n",
            "  batch 3000 loss: 1.9680192667245864\n",
            "  batch 4000 loss: 1.9675359259843825\n",
            "  batch 5000 loss: 1.9446904710531234\n",
            "  batch 6000 loss: 1.9231701859235764\n",
            "  batch 7000 loss: 1.9307630525827408\n",
            "  batch 8000 loss: 1.9204145077466965\n",
            "  batch 9000 loss: 1.9117811543941499\n",
            "  batch 10000 loss: 1.9058752139806747\n",
            "  batch 11000 loss: 1.9041150370836257\n",
            "  batch 12000 loss: 1.9067993041276932\n",
            "  batch 13000 loss: 1.8946286444664002\n",
            "  batch 14000 loss: 1.885815178990364\n",
            "LOSS train (1.885815178990364, 0.4790014749426103) valid 1.950008749961853\n",
            "valid 0.48041095890410956\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 1.8867945058345794\n",
            "  batch 2000 loss: 1.8931945152282714\n",
            "  batch 3000 loss: 1.8849522304534911\n",
            "  batch 4000 loss: 1.890642570257187\n",
            "  batch 5000 loss: 1.8807494660615922\n",
            "  batch 6000 loss: 1.8810622565746307\n",
            "  batch 7000 loss: 1.8811723428964615\n",
            "  batch 8000 loss: 1.877561089515686\n",
            "  batch 9000 loss: 1.8786720273494721\n",
            "  batch 10000 loss: 1.8898491034507752\n",
            "  batch 11000 loss: 1.8818139961957931\n",
            "  batch 12000 loss: 1.8740506284236909\n",
            "  batch 13000 loss: 1.875784682393074\n",
            "  batch 14000 loss: 1.8819546408653258\n",
            "LOSS train (1.8819546408653258, 0.4969708227518215) valid 1.9310057163238525\n",
            "valid 0.4887945205479452\n",
            "EPOCH 3:\n",
            "  batch 1000 loss: 1.8681905611753464\n",
            "  batch 2000 loss: 1.8591651381254197\n",
            "  batch 3000 loss: 1.8643314250707625\n",
            "  batch 4000 loss: 1.868491690993309\n",
            "  batch 5000 loss: 1.87305071747303\n",
            "  batch 6000 loss: 1.8662218940258026\n",
            "  batch 7000 loss: 1.8674299775362015\n",
            "  batch 8000 loss: 1.8652363512516021\n",
            "  batch 9000 loss: 1.8667234605550767\n",
            "  batch 10000 loss: 1.8759188235998154\n",
            "  batch 11000 loss: 1.861650549173355\n",
            "  batch 12000 loss: 1.8712005993127823\n",
            "  batch 13000 loss: 1.871073217511177\n",
            "  batch 14000 loss: 1.8613535432815551\n",
            "LOSS train (1.8613535432815551, 0.5006443170350326) valid 1.9370191097259521\n",
            "valid 0.48663013698630136\n",
            "EPOCH 4:\n",
            "  batch 1000 loss: 1.8429069702625274\n",
            "  batch 2000 loss: 1.8637516136169434\n",
            "  batch 3000 loss: 1.8604262436628343\n",
            "  batch 4000 loss: 1.8617456831932069\n",
            "  batch 5000 loss: 1.8613958047628403\n",
            "  batch 6000 loss: 1.8682454771995545\n",
            "  batch 7000 loss: 1.8682217589616776\n",
            "  batch 8000 loss: 1.86030515396595\n",
            "  batch 9000 loss: 1.8510539798736572\n",
            "  batch 10000 loss: 1.8667954716682433\n",
            "  batch 11000 loss: 1.8586829479932785\n",
            "  batch 12000 loss: 1.8563729753494262\n",
            "  batch 13000 loss: 1.865866473197937\n",
            "  batch 14000 loss: 1.8574050103425979\n",
            "LOSS train (1.8574050103425979, 0.5019895090548169) valid 1.9118314981460571\n",
            "valid 0.4931506849315068\n",
            "EPOCH 5:\n",
            "  batch 1000 loss: 1.8519561750888824\n",
            "  batch 2000 loss: 1.8536654784679414\n",
            "  batch 3000 loss: 1.850600352883339\n",
            "  batch 4000 loss: 1.8574619839191437\n",
            "  batch 5000 loss: 1.8458626577854156\n",
            "  batch 6000 loss: 1.8553948075771332\n",
            "  batch 7000 loss: 1.849032398223877\n",
            "  batch 8000 loss: 1.8593433765172958\n",
            "  batch 9000 loss: 1.8644231371879578\n",
            "  batch 10000 loss: 1.8500726102590561\n",
            "  batch 11000 loss: 1.8634097446203233\n",
            "  batch 12000 loss: 1.8646535794734955\n",
            "  batch 13000 loss: 1.8610492607355118\n",
            "  batch 14000 loss: 1.8653164316415787\n",
            "LOSS train (1.8653164316415787, 0.5034866312532577) valid 1.9176095724105835\n",
            "valid 0.49205479452054796\n"
          ]
        }
      ],
      "source": [
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    big.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    big.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(test_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            vinputs, vlabels = vinputs.cuda(), vlabels.cuda()\n",
        "            voutputs = big(vinputs)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            _, vpredicted = torch.max(voutputs.data, 1)\n",
        "            total += vlabels.size(0)\n",
        "            correct += (vpredicted == vlabels).sum().item()\n",
        "\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    val_accuracy = correct / total\n",
        "\n",
        "    print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
        "    print(f'valid {val_accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}'.format(epoch_number)\n",
        "        torch.save(big.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'hybrid_model.pth'\n",
        "torch.save(big.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "O5g5SFWoCVn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7jZAWtYSThrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}